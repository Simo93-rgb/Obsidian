# Analisi di taxonomy.py

Il file `taxonomy.py` contiene due classi che gestiscono le relazioni tassonomiche tra token (attività) in un vocabolario. Queste classi sono utilizzate per arricchire le rappresentazioni del modello Proformer con informazioni sulle relazioni tra le diverse attività.

## Classe Taxonomy

La classe `Taxonomy` crea e gestisce matrici di pesi che rappresentano le relazioni tra i token:

1. **Funzionalità principali**:
   - Carica relazioni tassonomiche da un file [[4. Taxonomy#Pickle|pickel]]
   - Crea una matrice completa di distanze tra tutti i token
   - Normalizza i pesi delle relazioni usando [[6. Reti Neurali#Softmin|Softmin]]

2. **Metodi chiave**:
   - `merge_dicts`: Crea un mapping completo di relazioni tra token
   - `get_norm_path`: Normalizza i valori di distanza con [[6. Reti Neurali#Softmin|Softmin]]
   - `get_all_weights`: Genera la matrice di pesi normalizzata
   - `get_weights`: Recupera i pesi per un token specifico

3. **Scopo**: Fornire una rappresentazione numerica delle relazioni tassonomiche che può essere utilizzata dal modello Transformer per arricchire gli embedding.

## Classe TaxonomyEmbedding

La classe `TaxonomyEmbedding` genera embedding basati su grafi per i token:

1. **Funzionalità principali**:
   - Carica una tassonomia da file CSV
   - Costruisce un grafo di relazioni tra token
   - Applica tecniche di graph embedding:
     - [[0. Presentazione e Teoria Necessaria#**Laplacian Eigenvector Positional Encoding**|Laplacian eigenvector positional encoding]]
     - [[0. Presentazione e Teoria Necessaria#**Random Walk Positional Encoding**|Random walk positional encoding]]

2. **Metodi chiave**:
   - `load_taxonomy`: Importa relazioni da CSV
   - `get_graph`: Costruisce un grafo NetworkX e lo converte in formato PyTorch Geometric

3. **Scopo**: Generare embedding che catturano la posizione di ogni token nella gerarchia tassonomica, utilizzando tecniche avanzate di graph embedding.

Entrambe le classi servono ad arricchire il modello Proformer con informazioni strutturali sulle relazioni tra le attività nei processi analizzati.

### **Riassumendo in parole semplici**

Stiamo creando **rappresentazioni numeriche** (embedding) per ogni elemento (token) in una struttura organizzata a livelli (come un albero). Queste rappresentazioni riflettono **dove si trova ogni elemento nella struttura** (vicino alla radice, vicino alle foglie, ecc.) e **come è collegato agli altri elementi** . Per farlo, usiamo metodi avanzati che analizzano il grafo formato dalla struttura gerarchica.

# Pickle
Un **file pickle** è un file che contiene dati serializzati utilizzando il modulo `pickle` di Python. Il modulo `pickle` è una libreria standard di Python che consente di convertire oggetti Python in un formato binario (serializzazione) e di ricostruirli successivamente (deserializzazione). Questo processo è utile per salvare oggetti complessi su disco o trasmetterli su una rete.

## Cosa fa il modulo `pickle`?

Il modulo `pickle` permette di:

1. **Serializzare** : Convertire un oggetto Python (come liste, dizionari, classi, ecc.) in un flusso di byte che può essere salvato su un file o trasmesso.
2. **Deserializzare** : Ricostruire l'oggetto originale da un flusso di byte precedentemente serializzato.

## Come funziona?

Ecco un esempio pratico di serializzazione e deserializzazione con `pickle`:

### Serializzazione (salvataggio su file)
```python
import pickle

# Oggetto da serializzare
data = {"nome": "Mario", "età": 30, "interessi": ["programmazione", "sport"]}

# Serializza l'oggetto e salvalo su un file
with open("dati.pkl", "wb") as file:  # 'wb' indica modalità scrittura binaria
    pickle.dump(data, file)
```
### Deserializzazione (lettura da file)
```python
import pickle

# Deserializza l'oggetto dal file
with open("dati.pkl", "rb") as file:  # 'rb' indica modalità lettura binaria
    dati_caricati = pickle.load(file)

print(dati_caricati)
# Output: {'nome': 'Mario', 'età': 30, 'interessi': ['programmazione', 'sport']}
```