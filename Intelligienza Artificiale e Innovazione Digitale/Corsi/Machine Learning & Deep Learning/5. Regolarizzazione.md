Quando si lavora con il machine learning ci sono due aspetti fondamentali:
1. **BIAS**: sono delle assunzioni eterogenee che vincolano il modello, anche sbagliate. Ad esempio se voglio che il modello sia lineare allora assumo che il mio modello lo sia e la situazione è vincolata così. Bias significa pregiudizio. Se il mio modello fitta poco i dai allora si parla di *underfitting*. Quindi il mio modello ha un alto bias ossia che i vincoli sono troppo stringenti e non si adatta al training set. Può anche voler dire che il modello sia troppo semplice. 
2. **Varianza del Modello**: il modello cambia significativamente anche con piccole fluttuazioni di dati del training set. È un modello che fitta troppo i dati che ha visto e quindi è paragonabile al ripetere "a pappagallo" ma questo è un problema poiché non generalizza. Attenzione, non c'è correlazione con varianza statistica. 

![[Machine Learning - Regolarizzazione - Regularization.png]]
<p align="center"><em>Caso regressione</em></p>

![[Machine Learning - Regolarizzazione  - classificazione.png]]
<p align="center"><em>Caso logic regression</em></p>

### Gestione overfitting
1. Posso ridurre il numero di features e posso farlo manualmente oppure posso farlo con un algoritmo
2. Regolarizzazione

## Regolarizzazione: funzione di costo
È un meccanismo matematico che funziona sulla funzione di costo, sostanzialmente tiene tutte le features ma riduce il valore dei parametri $\Theta_j$. 
![[Machine Learning - Regolarizzazione  - funzione di costo.png]]
Intuitivamente si potrebbe pensare di ridurre le features più grandi per ottimizzare la funzione di costo
$$min_\Theta J(\Theta)= \frac{1}{2m} {\sum_{i=1}^m (h_\Theta(x^i)-y^i)^2 +\alpha\Theta_3+\beta\Theta_4}$$
Il passo successivo è lasciar decidere all'algoritmo quale penalizzare senza dare precedenza alle più grandi. Attenzione che $\Theta_0$ è l'unico che non si regolarizza mai. In generale: $$min_\Theta J(\Theta)= \frac{1}{2m} {\sum_{i=1}^m (h_\Theta(x^i)-y^i)^2 \lambda \sum_{i=1}^n\Theta_j^2}$$
*Attenzione che $\lambda$ è il parametro di regolarizzazione*. Una scelta erronea di $\lambda$ porta ad una semplificazione eccessiva del modello rischiando di avere underfitting. 
Osservazione: $\sum_{i=1}^n\Theta_j^2$ è la norma del vettore $\Theta$, indicato con $\|\Theta\|_2$. Più la norma è grande più le features dentro al vettore contano. 
![[Machine Learning - Regolarizzazione  - andamento regolarizzazione.png]]
<p align="center"><em>da notare che al crescere di alpha io ho comunque un buon fit ma mi allontano dall'avere overfitting, fino al degenerare</em></p>
Da notare che $\alpha$ viene anche chiamato **parametro di ridge**. 

### Regolarizzazione: regolarizzare la regressione lineare
Aggiungendo alla discesa del gradiente il fattore di correzione $-\frac{\lambda}{m}\Theta_j$.
![[Machine Learning - Regolarizzazione  - algo regolarizzazione lineare.png]]
### Regolarizzazione: regolarizzare la logic regression
La funzione di costo, ossia la cross entropy, si vede aggiungere il fattore $+\frac{\lambda}{2m}\sum_{i=1}^n\Theta_j^2$. Grazie a questo posso applicare la stessa logica vista qui sopra. 