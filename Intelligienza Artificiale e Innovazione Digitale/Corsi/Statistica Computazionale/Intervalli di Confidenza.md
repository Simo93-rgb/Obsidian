Gli intervalli di confidenza sono come delle "zone di incertezza" attorno a una stima statistica, come la media di un campione o un parametro di una popolazione. In sostanza, forniscono un intervallo entro il quale è probabile che si trovi il vero valore del parametro.
Ad esempio, se calcoli l'intervallo di confidenza del 95% per la media di un campione, significa che c'è una probabilità del 95% che il vero valore della media della popolazione si trovi all'interno di quell'intervallo. È un modo per esprimere la precisione della tua stima e tener conto della variabilità dei dati campionati. Insomma, una sorta di margine di errore che aiuta a capire quanto puoi fidarti della tua stima.
In tutti i [[Metodi Montecarlo]] visti precedentemente possiamo calcolare un intervallo di confidenza così definito $$IC_{(1-\alpha)}=\hat\Theta \pm z_{(1-{\alpha\over2})}*se(\hat\Theta)$$Noi in **R** rappresentiamo $z_{(1-{\alpha\over2})}$ con ``qnorm(1-alpha)`` e ad esempio con $\alpha=0.1$ abbiamo ``qnorm(0.90)``. $z_{(1-{\alpha\over2})}$ è quantile di $\mathcal{N}(0,1)$ d'ordine $1-\alpha$. $$\mathbb{P}\bigg(\Theta \in \big(\hat\Theta - z_{(1-{\alpha\over2})}*se(\hat\Theta);\hat\Theta + z_{(1-{\alpha\over2})}*se(\hat\Theta) \big) \bigg)=1-\alpha$$
Da notare che $IC_{(1-\alpha)}$ è un intervallo casuale perché dipende dal campione. 


