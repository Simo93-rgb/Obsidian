# Teorema del Limite Centrale
Supponiamo di voler censire qualcosa per il quale la dimensione √® fuori dalla nostra portata, che faccio? Mi arrendo? NO! Misuro un campione la cui dimensione √® alla mia portata e cerco di avere il mio campione che sia il pi√π possibile fedele a quel che volevo misurare in origine. Supponendo che $Y = \{X_1, ... , X_n\}$ dove le $X$ sono i mie esperimenti (misuro l'altezza delle persone e $X_i$ √® l'i-esima persona che misuro). $Y$ √® quindi il mio esperimento di cui ho bisogno di misurare un suo parametro come la media, la pdf etc... Ecco, definiamo $\Theta$ che rappresenta proprio quel parametro incognito. Adesso ho bisogno di uno stimatore per $\Theta$ che chiamer√≤ $T$, intuitivamente noi degli stimatori li abbiamo gi√† visti: $$\begin{cases}\bar x_n = {1 \over n}\sum_{i=1}^n x_i & \text{media campionaria √® stimatore di }\mu \\ S^2 = {1 \over n-1}\sum_{i=1}^n (x_i - \bar x_n ) & \text{varianza campionaria √® stimatore per } \sigma^2 \end{cases}$$
Noi sappiamo che media campionaria e varianza campionaria sono stimatori corretti, rispettivamente, per media e per varianza quindi possiamo scrivere $\mathbb{E}[\bar x_n] = \mu$ e possiamo anche scrivere che $\mathbb{E}[S^2] = \sigma^2$. Ma quindi, se voglio che $T$ sia uno stimatore corretto di $\Theta$ deve per forza valere $\mathbb{E}[T] = \Theta$. Posso anche parlare di *stimatore asintotico* se vale che per $\lim_{n \rightarrow +\infty}$ del mio stimatore $T$ ottengo come valore atteso $\Theta$. 
Possiamo esprimere il concetto di correttezza anche passando per la varianza e lo faccio a parole che tanto √® intuitivo: al crescere della taglia campionaria la varianza si riduce avendo come risultato del $\lim_{n \rightarrow +\infty}$ uno zero che rappresenta uno scostamento nullo dal valore vero. 
Il TLC ci dice con quale distribuzione la nostra media campionaria converge alla media vera e lo fa definendo due casi:

|$\sigma$ nota|$\sigma$ incognita|
|:------:|:----------:|
|$Z = {\bar X_n - \mu \over {\sigma \over \sqrt{n}}} \sim N(0,1)$ |$T = {\bar X_n - \mu \over {S \over \sqrt{n}}} \sim N(0,1)$ |

Attenzione che deve valere sempre che $n$ sia grande. Per√≤ fino ad ora non abbiamo definito cosa significa "grande" e con che considerazioni devo prendere questo $n$. 
Se $n$ √® qualsiasi e $\sigma$ incognita allora si distribuisce come una $T \sim t_{n-1}$. 
# Legge dei Grandi Numeri
Cos'√®? Se il TLC ci dice come converge la media campionaria la LGN ci dice *a cosa converge.* Ce ne sono due versioni dette LGN Debole e LGN Forte. 

## LGN Debole
Qui esprimo il concetto di **tolleranza sempre positiva**, che rappresento con $\varepsilon$. $$\lim_{n \rightarrow +\infty} \mathbb{P}(|\bar x_n - \mu| > \varepsilon) = 0$$
**Dove**:
- $|\bar x_n - \mu|$ rappresenta l'errore di misura della media campionaria rispetto al valore vero
- $\varepsilon$ √® la tolleranza

## LGN Forte
Questa √® pi√π semplice $$\mathbb{P}\bigg(\lim_{n \rightarrow +\infty}\bar x_n = \mu \bigg)=1$$
*√à tautologico che con n che tende a infinito la media campionaria sia esattamente il valore vero*. Attenzione che come affermazione √® davvero forte. 

## Considerazioni Importanti su TLC e LGN
Finalmente possiamo dire che $n$ √® grande se arrivo ad una taglia campionaria ci circa 40 elementi, anche se poi andando su R sar√† facile vedere come sotto le centinaia l'errore commesso non √® cos√¨ piccolo. 
TLC e LGN sono *distribution free* ossia che valgono in modo indipendente dal tipo di distribuzione. 

|----------|$\sigma$ nota|$\sigma$ non nota|
|:-:|:-------------------------------:|:--------------------------:|
|$X \sim Gaussiana \land n \text{ qualsiasi}$|$Z \sim N(0,1)$|$T \sim t_{n-1}$|

Se $X$ √® una qualsiasi vc ed $n$ √® grande $\Longleftrightarrow$ $T \sim Z \sim N(0,1)$. In altre parole, se $X$ √® una vc di una distribuzione qualsiasi e la taglia campionaria √® molto grande allora il mio stimatore $T$ lo posso approssimare come visto nel TLC. 

# $t-student$
Introduciamo questa distribuzione complicata ma utile poich√© arriva da uno studio fatto alla Guinness e se c'√® della birra di mezzo non si pu√≤ non parlarne üòÇüçª. √à la generalizzazione della $N(0,1)$ con code pesanti. ![[TLC e LGN - t_student.png|450]]
Sicuramente val la pena andare a vederla su [Wikipedia](https://it.wikipedia.org/wiki/Distribuzione_t_di_Student)
Aumentando $n$ alzo il centro e mi porto ad avere una normale $\mathcal{N}\sim N(0,1)$ 