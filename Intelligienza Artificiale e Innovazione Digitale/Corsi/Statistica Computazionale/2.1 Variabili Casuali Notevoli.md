Per definire le vc notevoli si esprimer√† a parole cosa rappresentano e perch√© sono utili, verranno esplicitati $\mathbb{E}[\bullet]$ e $Var(\bullet)$. Per chiarezza, si parler√† di:
- *funzione di densit√† di probabilit√†* per le variabili casuali continue, d'ora in avanti abbreviato con *pdf - probability density function*
- *funzione di massa di probabilit√†* per le variabili casuali discrete, d'ora in avanti abbreviato con *pmf - probability mass function*
- *funzione di ripartizione* per entrambe le variabili, d'ora in avanti abbreviato con *cdf - cumulative density function*
	- √à una funzione che definisce la probabilit√† che la variabile abbia un valore minore o uguale  a qualcosa
	- $\begin{cases}F_X(x)=\mathbb{P}(X\le x)\\ \mathbb{P}(a\le X \le b)=F_X(b)-F_X(a)\end{cases}$
# Bernoulli
La distribuzione di Bernoulli serve a modellare un solo esperimento che potr√† avere un solo esito binario. Ad esempio il lancio di una moneta, ma attenzione che se lancio due monete mi servono due Bernoulli. Usando la solita $X$ per indicare una vc: $$X \sim Ber(\pi)$$ Dove $\pi \in [0,1] \subset \mathbb{N}$ 
$$X =\biggl\{ {0 \text{ se ho insuccesso} \atop 1 \text{ se ho successo}} \biggl\} $$
Indicando con $S$ il successo e con $\bar S$ l'insuccesso possiamo scrivere:
- $\mathbb{P}(S) = \mathbb{P}(X = 1) = \pi$
- $\mathbb{P}(\bar S) = \mathbb{P}(X = 0) = 1-\pi$
- $\mathbb{P}(X=x) = \pi^x(1-\pi)^{1-x}$
**PDF**
- $f_X(x)=\begin{cases} 1-\pi & x=0\\ \pi & x=1\\ 0 & \text{altrimenti}\end{cases}$
- ![[Variabili Casuali Notevoli - pdf Bernoulli.png|450]]
**CDF**
- $F_X(x)=\begin{cases} 0 & x<0\\ 1-\pi & 0\le x \le1\\ 1 & x>0\end{cases}$
- ![[Variabili Casuali Notevoli - cdf della bernoulli.png|450]]

**Valore atteso**: $\mathbb{E}[X] = \sum_{i=0}^1{x \mathbb{P}(X=x)} = \pi^0(1-\pi)^{1-0} + \pi^1(1-\pi)^{1-1} = \pi$ 
**Varianza**: $Var(X) = \mathbb{E}[X^2] - \big(\mathbb{E}[X] \big)^2 = \pi (1-\pi)$
Le dimostrazioni sono lasciate al lettore üòú


# Binomiale
Stavi pensando che fosse scemo avere due Bernoulli per due lanci di moneta? Ecco la soluzione! $$X \sim Bin(n, \pi)$$
Prendiamo $n$ esperimenti di Bernoulli indipendenti identicamente distribuiti, la nostra Binomiale serve a contemplare proprio tante Bernoulli in un unico esperimento, precisamente i suoi successi. Rappresentiamo con $Y$ una vc di Bernoulli, avr√≤ che $$X = \sum_{i=1}^n Y_i$$ e la sua distribuzione di probabilit√† √® $$\mathbb{P}(X=x) = {n \choose p}\pi^x(1-\pi)^{n-x}$$**Piccolo cenno**: il coefficiente binomiale ${n \choose p}$ indica con $n$ il numero di elementi dell'insieme e con $p$ gli elementi di un sottoinsieme, il risultato del coefficiente binomiale √® il numero di sottoinsiemi diversi fra loro con cardinalit√† $p$ che sono in grado di fare a partire da $n$. Se avessi ${4 \choose 2}$ il risultato sarebbe $6$ poich√© posso fare quel numero di sottoinsiemi diversi fra loro partendo da uno con cardinalit√† $4$. Per maggiori dettagli vedere il capitolo su [YouMath](https://www.youmath.it/lezioni/probabilita/calcolo-combinatorio/1515-coefficiente-binomiale.html)

**Valore atteso**: $\mathbb{E}[X] = \mathbb{E}\big[ \sum_{i=1}^n Y_i\big] = \sum_{i=1}^n\mathbb{E}[Y_i] = \sum_{i=1}^n \pi = n\pi$ 
**Varianza**: $$\begin{align} &\quad Var(X) = Var\big( \sum_{i=1}^n Y_i\big)=\sum_{i=1}^nVar(Y_i)=\\ &\quad  \sum_{i=1}^n \pi(1-\pi)=  n\pi(1-\pi)\end{align}$$
Da notare che $Var(Y_i) = \pi(1-\pi)$ nel passaggio dentro la sommatoria √® stato rubato dalla definizione nella Bernoulli.

# Poisson
Ma se avessi bisogno di una Binomiale ma non avessi a disposizione $n$ poich√© potenzialmente infinito? Ecco che la Poisson ci viene in aiuto. $$X \sim P(\lambda)$$
La $\lambda$ rappresenta il numero di eventi che ci si aspetta in un intervallo di tempo o spazio, infatti la Poisson va bene per casi come contare quante chiamate arrivano al call-center. 
La distribuzione di probabilit√† √® fatta cos√¨: $$\mathbb{P}(X=x) = e^{-\lambda}{\lambda^x \over x!}$$
# Normale o Gaussiana
Questa √® continua quindi devo parlare di funzione di densit√† di probabilit√† (pdf) per definirla, ma prima indichiamo come la rappresentiamo: $$X \sim N(\mu, \sigma^2)$$
La pdf della Gaussiana √® fatta cos√¨: $$f_X(x) = {1 \over  \sqrt{2\pi\sigma^2} } \exp \biggl\{  - {(x- \mu) \over 2\sigma}^2  \biggl\}$$
Finora sembra brutta come la fame ma la figata √® nell'espressione del valore atteso e della varianza:
- **Valore atteso**: $\mathbb{E}[X] = \mu$
- **Varianza**: $Var(X) = \sigma^2$

Ci sono alcune propriet√† che torneranno molto utili.
### Propriet√† Gaussiana
Per definire le propriet√† prima dobbiamo fare delle premesse:$$\begin{cases} X \sim N(\mu, \sigma^2) & \text{Gaussiana} \\ Y = a + bX & \text{ con }a,b \in \mathbb{R} \land b\not = 0 \end{cases}$$
1. $Y \sim N(\mu = a+n*\mu_X \text{, } \sigma^2 = b\sigma^2_X)$
2. $Z={X-\mu \over \sigma} \sim N(0,1)$
	1. Questa propriet√† √® detta *standardizzazione*
3. Siano $\{X_1, ..., X_n\}$ Gaussiane iid, posso combinarle linearmente ottenendo una vc $Y$ come segue: $Y = \sum_{i=1}^n a_i X_i \sim N(\mu = \sum_{i=1}^n a_i \mu_i, \sigma^2 = \sum_{i=1}^n a_i \sigma^2_i )$
# Uniforme
Sia $U \sim \mathcal{U}(0,1)$
- **PDF** 
	- $f_U(u)=\begin{cases}1 & 0\le 1 \\ 0 & \text{altrove}\end{cases}$
	+ ![[Variabili Casuali Notevoli - pdf di una U(0,1).png]]
+ **CDF** 
	+ $F_U(u)=\begin{cases}0 & x < 0 \\ u & 0\le x \le 1 \\ 1 & x > 1 \end{cases}=\mathbb{P}(U \le u)=\int_{-\infty}^u f_U(t)dt$  
	+ ![[Variabili Casuali Notevoli - cdf di una U(0,1).png]]
	+ $\mathbb{E}[U]={1\over 2}$
	+ $Var(U)={1\over 12}$
# Esponenziale
Altra vc continua da inserire nel nostro portafoglio √® la esponenziale $$X \sim exp(\lambda) \text{ con } \lambda >0$$Andiamo a definire le solite funzioni di densit√† e di probabilit√†

- **PDF** 
	- $f_X(x)=\begin{cases}0 & x\le 0 \\ \lambda e^{-\lambda x}& x>0\end{cases}$ 
	- ![[Variabili Casuali Notevoli - pdf esponenziale.png|250]]
	- I possibili esiti sono definiti da $supp\big\{(0,+\infty)\big\}$
- **CDF**
	- $F_X(x)=\begin{cases}0 & x\le 0 \\ 1- e^{-\lambda x}& x>0\end{cases}$
	- ![[Variabili Casuali Notevoli - cdf della esponenziale.png|250]]
La vc esponenziale √® stata inventata in ambito militare per misurare il tempo di rottura delle semiali dei velivoli. In generale infatti si usa per misurare i tempi di attesa, ad esempio l'intervallo di tempo fra un intervallo e l'altro in un call center. √à legata alla [[2.1 Variabili Casuali Notevoli#Poisson|Poisson]]e infatti se dovessi contare quante chiamate arrivano al call center uso la Poisson e fra queste ci sono tanti tempi di attesa che si modellano con la esponenziale. Quindi se conto quante vc esponenziali ho un valore distribuito come una Poisson. Ai fini dell'esame questa √® solo da ritenersi una curiosit√†. 

# Beta(2,2)
- **PDF**
	- ![[Variabili Casuali Notevoli - beta 2 2 pdf.png]]
	- $f_X(x)=\begin{cases} 6x(1-x)&0<x<1\\0&\text{altrove}\end{cases}$
- **CDF**
	- $F_X(X)=\int_{-\infty}^x f_X(t)dt=3x^2-2x^3$


