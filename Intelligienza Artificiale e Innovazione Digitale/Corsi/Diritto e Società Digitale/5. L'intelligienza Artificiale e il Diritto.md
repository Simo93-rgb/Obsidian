I primi due capitoli fanno cagare, di seguito un accenno al terzo e poi l'intero quarto capitolo

# L'IA: Opportunità, Rischi e Norme
## 3.6 Etica per l'IA

L'intelligenza artificiale (IA) rappresenta una delle principali sfide future per l'umanità, aprendo enormi opportunità di progresso ma portando anche significativi rischi, specialmente per quanto riguarda la formazione dell'opinione pubblica e il funzionamento dei processi democratici. L'IA può migliorare l'informazione dei cittadini e stimolare il dibattito pubblico, ma ha anche il potenziale di influenzare negativamente il dibattito democratico e le elezioni.

### 3.6.1 L'etica dell'IA

L'etica dell'IA si concentra su come sviluppare e utilizzare le tecnologie IA in modo eticamente corretto, assicurando che la loro applicazione rispetti norme e valori etici. È parte di una più ampia etica dell'informatica, che valuta i problemi morali relativi a dati, algoritmi, e le relative pratiche, promuovendo soluzioni morali come condotte corrette e valori appropriati. Il dibattito sull'etica dell'IA coinvolge studiosi, imprese digitali, istituzioni politiche, e la società civile, conducendo alla redazione di documenti che evidenziano valori comuni come trasparenza, non-maleficenza, responsabilità, privacy, dignità, e solidarietà.

### 3.6.2 I principi

Promuovere un uso eticamente positivo dell'IA significa assicurare che il suo sviluppo e impiego avvenga in un contesto che rispetti e promuova interessi individuali e valori sociali. Ciò richiede di aderire a principi astratti e fondamentali, che includono diritti fondamentali e valori sociali, sia a livello etico che giuridico. Documenti come AI4People e le linee guida dell'High-Level Expert Group on Artificial Intelligence enfatizzano l'importanza del rispetto per l'autonomia umana, la prevenzione del danno, l'equità, e la spiegabilità, come pilastri di un'IA affidabile.

### 3.6.3 Tre interessi da considerare

1. **Protezione dei dati**: È cruciale assicurare l'uso legittimo e proporzionato dei dati personali, proteggendoli da usi che potrebbero compromettere la privacy individuale.
    
2. **Trattamento algoritmico equo e corretto**: Bisogna evitare pregiudizi ingiustificati che possono emergere dalle elaborazioni automatiche, garantendo un trattamento equo.
    
3. **Trasparenza e spiegabilità algoritmica**: È fondamentale che gli individui possano comprendere come e perché vengono prese decisioni che li riguardano, garantendo così trasparenza e possibilità di contestazione.

## 3.7 Diritto per l'IA

### 3.7.1 L'IA nel Regolamento sulla protezione dei dati

Il Regolamento Generale sulla Protezione dei Dati (GDPR) stabilisce norme rilevanti per l'informazione, la profilazione e la decisione automatica. Sebbene non vieti la profilazione, richiede una base giuridica e procedure matematiche o statistiche appropriate. Il GDPR impone un divieto generale su decisioni completamente automatizzate che producono effetti significativi sugli individui, con ampie eccezioni consentite per contratti, leggi, o su base del consenso esplicito.

### 3.7.2 La proposta di un regolamento sull'IA

La Commissione Europea ha proposto un regolamento per disciplinare l'IA, basandosi su un approccio di gestione del rischio. Categorie di applicazioni di IA che presentano rischi inaccettabili sono vietate, come sistemi che utilizzano tecniche subliminali per alterare il comportamento, sistemi che sfruttano vulnerabilità di specifici gruppi di persone, e sistemi di valutazione o classificazione della affidabilità delle persone fisiche attraverso punteggi sociali. Il regolamento richiede trasparenza e supervisione umana per sistemi ad alto rischio.

### 3.7.3 La Proposta di Direttiva in tema di responsabilità extracontrattuale e IA

La Direttiva proposta affronta la responsabilità per danni causati da sistemi di IA ad alto rischio, facilitando l'acquisizione di elementi di prova e alleggerendo l'onere della prova per il danneggiato quando il convenuto ha violato un obbligo di diligenza.

### 3.7.4 Il contrasto alla disinformazione

Iniziative volte a contrastare la disinformazione online includono miglioramenti nella capacità di rilevamento e analisi, cooperazione tra piattaforme online, industria e società civile, e supporto al giornalismo di qualità. Il Codice di Pratica sulla Disinformazione e la sua versione rafforzata mirano a promuovere la trasparenza e la diffusione di informazioni autentiche.

### 3.7.5 La disciplina dei robot

La diffusione dei robot solleva nuovi problemi giuridici, compresa la responsabilità per i danni causati. I robot, essendo capaci di operare autonomamente e causare danni materiali, pongono interrogativi su come concepire giuridicamente il rapporto tra l'utilizzatore e il robot, e su come gestire la responsabilità.

### 3.7.6 Le armi intelligenti

L'uso di IA in applicazioni militari, incluse armi autonome, solleva questioni sul rispetto dei principi fondamentali del diritto umanitario, con molti che auspicano la proibizione o una moratoria sull'uso di armi robotiche autonome.

### 3.7.7 Tecnologie di IA per l'etica e il diritto

Per indirizzare l'IA verso il bene comune, è essenziale una cornice normativa che includa etica e norme giuridiche. Tuttavia, il potere crescente dell'IA richiede anche contropoteri da parte della società civile, che può utilizzare l'IA a proprio vantaggio per promuovere una cittadinanza attiva e democratica.

# L'IA: Applicazioni Giuridiche
Il quarto capitolo esplora in profondità le applicazioni giuridiche dell'IA, coprendo vari aspetti da sistemi basati su regole e apprendimento automatico fino ai dibattiti etici e giuridici che emergono dall'integrazione dell'IA nel campo legale.
### Sistemi Giuridici Basati sull'IA

Il capitolo inizia discutendo come l'intelligenza artificiale sia applicata per interpretare e applicare le leggi, evidenziando due approcci principali: sistemi basati su regole e apprendimento automatico. I sistemi basati su regole utilizzano un insieme predefinito di regole legali per formulare giudizi, mentre l'apprendimento automatico analizza grandi dataset di decisioni passate per prevedere esiti futuri. Entrambi gli approcci presentano vantaggi e sfide, inclusa la necessità di trasparenza e l'abilità di adeguarsi a contesti legali complessi.

### Giustizia Predittiva e Precedenti Giuridici

Il documento approfondisce l'uso dell'IA nella predizione di decisioni giudiziarie, noto come giustizia predittiva. Questa sezione esplora come l'IA possa analizzare precedenti giuridici per prevedere l'esito di casi futuri, sollevando questioni sulla potenziale riduzione della giustizia a mere probabilità statistiche e sull'impatto sul principio di equità.

### Etica e Regolamentazione dell'IA nel Diritto

Una parte significativa del capitolo è dedicata alle implicazioni etiche e alle necessità di regolamentazione dell'uso dell'IA nel settore legale. Viene discusso come l'IA possa sia migliorare l'accesso alla giustizia che presentare rischi di bias e discriminazione, evidenziando la necessità di un quadro normativo che bilanci innovazione e protezione dei diritti fondamentali.

### IA e Pratica Legale

Il capitolo esamina anche l'impiego dell'IA nella pratica legale quotidiana, dal supporto nella ricerca legale alla redazione di documenti e alla gestione del contenzioso. Viene sottolineata l'importanza di sistemi di IA che assistono gli avvocati anziché sostituirli, promuovendo un'interazione che valorizzi l'expertise umana.

### Sfide e Opportunità

Infine, vengono discusse le sfide poste dall'integrazione dell'IA nel diritto, come la necessità di formazione legale specifica per gli sviluppatori di IA e la creazione di meccanismi di accountability per le decisioni automatizzate. Allo stesso tempo, il capitolo mette in luce le opportunità offerte dall'IA per rendere il sistema giudiziario più efficiente e accessibile.

# Conclusione
Come si è osservato nella prefazione, il presente volume si propone di introdurre il giurista all’intelligenza artificiale, con un’esposizione sintetica e accessibile anche a chi sia privo di conoscenze tecniche, ma non superficiale.

Spero che il lettore, giunto alla fine del volume, possa disporre di alcuni strumenti per meglio cogliere la dinamiche tecnologiche e sociali dell’IA, e forse anche per contribuire ad indirizzarle.

L’intelligenza artificiale ha infatti bisogno del diritto; solo grazie ad un’efficace disciplina giuridica l’IA potrà svilupparsi nel rispetto delle esigenze individuali e dei valori sociali. Si tratta di una condizione meramente necessaria, non sufficiente per tale obiettivo: sono altresì necessari sviluppi tecnologici nella direzione di un’intelligenza artificiale “centrata sull’uomo” (_human centred AI_), che il diritto può tuttavia contribuire a promuovere.

Il diritto, d’altro lato, ha bisogno dell’intelligenza artificiale, le cui tecnologie possono contribuire a migliorare il lavoro del giurista, e l’efficienza-efficacia del sistema giuridico. Tali tecnologie sono necessarie, in particolare, per affrontare tematiche collegate alla tecnologie dell’informazione e alla stessa intelligenza artificiale (es. il controllo su informazioni e interazioni online, la verifica della legalità ed equità degli algoritmi, ecc.) Più in generale l’IA può contribuire a rendere maggiormente informata e consapevole l’attività del giurista, potenziandone le capacità di analisi e decisione.

I due bisogni appena menzionati potranno essere soddisfatti solo se il giurista potrà contribuire in modo efficace e consapevole alla regolazione dell’IA e al suo uso nel diritto. Spero che questo lavoro possa rappresentare un modesto ma utile contributo in questa direzione.