Il **CBR** √® una metodologia per risolvere problemi nuovi adattando le soluzioni di problemi simili precedenti; conosciuti come *sistemi esperti*.

![[Case-Based reasoning - CBRschema 2.png|350]]

>‚Äú.... transferring knowledge from past problem solving episodes to new problems that share significant aspects with corresponding past experience and using the transferred knowledge to construct solutions to new problems.‚Äù
>Carbonell, 1986
## Esempi di CBR
- **Classificazione** $\rightarrow$ di un paziente clinico in base alla sintomatologia/esami
- **Soluzione Compilata** $\rightarrow$ ossia la spiegazione del problema $x$ √® derivabile da quello gi√† visto col problema $y$
- **Valutazione del Valore** $\rightarrow$ ossia verificare il valore di qualcosa osservando l'ambiente
- **Giustificare coi Precedenti** $\rightarrow$ ossia risolvere il problema nello stesso modo in cui si √® risolto un precedente. Un po' come accade nella legislatura anglosassone. 
- **Valutazione delle Opzioni** $\rightarrow$ ossia valutare le possibili conseguenze in base a cosa √® successo nei casi simili. "*Se attaccassimo la base missilistica Cuba/Russia otterremo una situazione come Pearl Harbor*"

#### Architettura R4
![[Case-Based Reasoning - architettura CBR dal libro.png|400]]
0. **Problem**: descrivo il problema da risolvere con una *tupla* di attributi. Il problema √® il punto di partenza dello schema
1. **Retrieve**: passo di recupero dai *previous cases* per recuperare i casi pi√π simili che sono presenti in memoria. 
	1. **Retrieved Case**: ho recuperato un caso simile
		1. **Solved Case**: ho una soluzione proposta
	2. **New Case**: il mio problema non √® simile a nessun caso in memoria
2. **Reuse**: se ho un caso simile lo uso altrimenti vado al revise.
3. **Revise**: avendo la *domain knowledge* posso fare questo passo. Ad esempio provo a dare un antibiotico differente ma questo adattamento ha bisogno di essere costruito con conoscenza del dominio.
	1. Se la soluzione √® adoperabile allora confermo la soluzione, altrimenti fallisco
4. **Retain**: il caso esaminato lo voglio aggiungere in memoria per ampliare la KB? 
	1. Caso fallito: interessante inserirlo cos√¨ un esperto del dominio inserisce la soluzione e lui per la prossima volta sapr√† qualcosa in pi√π.
	2. Retrieved Case: non ha senso aggiungere perch√© gi√† lo avevo in memoria gi√† molto simile e diventa uno spreco di memoria oltre che, molto peggio, i sistemi vanno in tilt se ci sono troppi dati.
Curiosit√†, il primo schema √® del 1993! 

### Come rappresento i casi?
Un caso √® un insieme di attributi e quindi la prima cosa da fare √® decidere quali e quanti attributi voglio avere per definire i casi. Gli attributi vengono chiamati *features*. Nel caso di un auto, ad esempio, posso avere un record (tupla, oggetto...) contenente et√†, cilindrata, potenza, colore, modello, marca etc. 
La *rappresentazione minima* consiste nel salvare la descrizione del caso e la sua soluzione. Posso avere delle *estensioni* per ampliare la conoscenza come ad esempio link ad altri casi, contesto, outcome relativi (fallimento, successo). 
![[Case-Based Reasoning - esempio struttura casi con CBRWorks.png|400]]
#### Indicizzazione
Le strategie di indicizzazione servono per recuperare i casi e per come eseguire il match. Quando si indicizza bisogna capire quali sono le features necessarie per discriminare i casi. 

## Modelli di Memoria
Esistono vari modi per recuperare i casi:
- [[2.2 Case-Based Reasoning#Memoria Piatta|Memoria Piatta]]
- Memorie Strutturate
	- [[2.2 Case-Based Reasoning#Decision Tree|Alberi di decisione (Classificazione)]]
	- k-d tree
- Database Relazionale/Oggetti
- Diversi Algoritmi di ricerca
	- L'algoritmo dipender√† da cosa cerco e quale complessit√† posso tollerare

### Memoria Piatta
I casi saranno delle tuple di features salvate. In sostanza la mia memoria √® un grosso insieme di features e il mio caso sar√† una tupla che punta a tutte le features che descrivono il caso. Una sorta di array di puntatori che puntano agli attributi desiderati. Poi quali algoritmi e che complessit√† dipende dall'implementazione. 

### Decision Tree
Spoiler: nel machine learning sono importantissimi. Un albero di decisione, o DT (Decision Tree), √® un albero dove:
- I nodi sono attributi
- Gli archi uscenti sono etichettati con condizioni sui valori dell'attributo
Questi alberi sono spesso usati per problemi di classificazione dove la soluzione √® appunto una classe (paziente di classe semplice o classe complessa?). Le foglie dell'albero indicizzano un insieme di casi e tengo traccia di quanti casi ci sono nelle varie classi (soluzioni). 
Come preannunciato in ML √® frequente questo tipo di struttura e un algoritmo molto noto √® il C4.5 (si for tu faive üòÇ).

![[Case-Based Reasoning - Esempio Decision Tree Tennis.png|450]]
Dando in pasto questa tabella ad un algoritmo C4.5 otterremmo, ad esempio, questo albero![[Case-Based Reasoning - Albero del tennis.png|400]]
Rispettivamente da sinistra a destra: (D1,D5) (D2,D3,D4) (D6,D7,D8,D9) (D10,D11) (D12,D13,D14)
Ok, tutto bello, ma cosa me ne faccio? √à utilissimo nel passo di retrieve in quanto se il caso nuovo ha tutti gli attributi allora mi basta navigare l'albero e trovare la classe corrispondente. Ma anche nella situazione in cui il caso √® incompleto, ad esempio manca il dato umidit√†, posso comunque navigare e dove non ho pi√π una evidenza mi baster√† prendere tutto il sotto albero a partire dal dato mancante. In questo ultimo caso avendo tre classi su cinque che dicono di giocare allora la soluzione √® ragionevolmente quella di giocare. 
# Similarit√† e Distanza
Cosa significa che due casi sono simili fra di loro? Possiamo impostare un parallelismo fra distanza e similarit√† per poi misurare quest'ultima in termini di distanza. Una metrica o distanza √® una una funzione su un insieme $X$ definita come $d: X\times X\rightarrow \mathbb{R}$ che rispetta questi requisiti: $$\begin{align}d(x,y)=0\Leftrightarrow x=y\\d(x,y)\le d(z,x)+d(z,y)\end{align}$$Corollari: $$\begin{align}1.&\quad 1. d(x,y) \geq 0 \\ 2.&\quad d(x,y) = d(y,x) \text{ Simmetria}\end{align}$$
##### Tipi di Distanze
Definiamo le distanze per un generico spazio $\mathbb{R}^n$:
1. Distanza di Manhattan $\rightarrow \sum_{i=1}^n{|x_i-y_i|}$
2. Distanza Euclidea $\rightarrow \sqrt{\sum_{i=1}^n{|x_i-y_i|}^2}$
3. Distanza di Minkowski $\rightarrow \sqrt[p]{\sum_{i=1}^n{|x_i-y_i|}^p} \text{ con } p\geq1$
4. Distanza discreta di overlap $d(x,y)=\begin{cases}0 \text{ se }x=y\\ 1 \text{ se } x\neq y\end{cases}$ 

## Matching
Ogni caso ha $n$ attributi chiamati features, questi possono essere visti come punti in uno spazio $\mathbb{R}^n$. Con questa nozione posso misurare una distanza fra casi esattamente come misurerei una distanza fra due punti nello spazio. 
Ci sono tecniche basate k-NN (k Nearest Neighbour).
### k-NN
Si definisce una funzione di distanza tra i valori di ogni features e successivamente posso misurare la distanza fra le features del caso in input e quelli nella KB; eventualmente si possono definire dei pesi per differenziare l'importanza di delle features. Ora si scelgono i $k$ casi pi√π vicini al target e si usano le loro soluzioni come base per la soluzione del caso target. 
![[Case-Based Reasoning - kNN a due dimensioni.png|400]]
#### Diagrammi di Voronoi
Divido il piano in regioni in base ad un insieme di punti dato e ad una funzione di distanza $d$. Ogni regione o partizione $R$ √® associata ad un punto $x$ e $\forall y\in R$ si ha che $x$ √® il punto pi√π vicino ad $y$ rispettando la distanza $d$.
![[Case-based Reasoning - Voronoi.png|400]]
#### Pesatura Attributi
Se $X$ e $Y$ sono ugualmente importanti, la distanza aumenta allo stesso modo in entrambe le direzioni (circonferenza)![[Case-Based Reasoning - pesatura attributi circonferenza.png|250]]Se $Y$ √® pi√π importante di $X$, piccole variazioni di $Y$ mi rendono i punti pi√π distanti su quell'asse e quindi viene fuori una ellisse schiacciata lungo $Y$; vale il viceversa.
![[Case-Based Reasoning - pesatura Attributi ellissica.png|250]]


##### Tipologia Attributi (features)
Possono essere nominali (categorici) o lineari. Nel caso dei nominali abbiamo colori, simboli... Mentre i lineari possono essere discreti o continui e nel caso discreto c'√® un caso che pu√≤ confondere: attributi lineari discreti simbolici. Succede quando mappo con dei numeri dei concetti, ad esempio una temperatura alta √® simbolico ma posso mapparla con 39¬∞C. 

### Metriche su Features
![[Case-Base Reasoning - metriche e features.png]]
dove $range_f = val_{max} - val_{min}$ 
Funziona male su features nominali per√≤. In alternativa si pu√≤ usare una tabella di similarit√† ![[Case-Base Reasoning - Tabella Similarit√† features nominali.png]]

### Heterogeneus Value Distance Metric
![[Case-Base Reasoning - HVDM.png]]
#### Esempio
![[Case-Base Reasoning - esempio HVDM.png]]
$d_f(chiaro,scuro)=0.225=$
$=\sqrt{|\mathbb{P}(M|chiaro)-\mathbb{P}(M|scuro)|^2+|\mathbb{P}(F|chiaro)-\mathbb{P}(F|scuro)|^2}$

## Implementazione k-NN
Siccome la ricerca lineare √® molto costosa con problemi grandi esiste l'applicazione dei *kd-trees* che √® $\mathbb{O}(log (n))$ ma siccome l'implementazione √® incredibilmente fastidiosa da mantenere alla fine lo sweet spot √® l'utilizzo della ricerca lineare.
Osservazione: se vuoi fare il figo parla di questa parte ma all'esame non viene chiesta.

# Adattamento
Siccome √® difficile definire delle strategie generali si cerca di definire delle regole ad-hoc a seconda del dominio. Ci sono due approcci: *transformational adaptation* e *derivational adaptation*.

## Trasformational Adaptation
Supponiamo che nel caso del riuso di un caso noto ho un problema di utilizzo della soluzione, ad esempio paziente allergico all'antibiotico, posso modificare la soluzione o aggiungendo un pezzo alla soluzione:
- Cambia antibiotico X con Y
- Dai antibiotico X ma con farmaco W antistaminico
## Derivational Adaptation
Tengo traccia non solo delle soluzioni ai casi ma anche di come ci sono arrivato e quando cerco nei casi conosciuti riapplico il metodo con cui nel caso noto arrivai al risultato. Ho usato una dimostrazione per assurdo in un caso matematico, se il caso √® simile la soluzione la cerco riapplicando il metodo per assurdo.

# Retain 
Qui si decide quando si deve apprendere ma anche quando si deve dimenticare un caso. Lo scopo √® tenere in memoria solo i casi utili altrimenti va in tilt il sistema. Nel Machine Learning e in particolare nel CBR si sente spesso parlare di utilit√†, di come definirla e di quali siano i suoi limiti. Non sempre vale il concetto che pi√π si sa e meglio √®, ingurgitare qualunque caso, anche se buono, porta a problemi. Prende il nome di *swamping problem* nel CBR e in generale nel ML si chiama *utility problem*.
![[Case-Base Reasoning - CBR grafico per swamping problem.png]]
La performance dipende da: 
- Tempo di esecuzione
- Qualit√† della risposta
- Competenza del sistema
Queste tre misure di performance dipendono sia dal numero di casi in memoria sia dalla qualit√† dei casi in memoria. Il problema di utilit√† √® trovare il numero di casi e la qualit√† dei casi che massimizzano la prestazione del CBR ma siccome non c'√® una ricetta generale che funziona bisogna esaminare caso per caso. Esistono anche altri problemi minori rispetto al utility problem.

## Curse of Dimensionality
Gli approcci *lazy learning* funzionano tanto peggio quanto maggiore √® il numero delle dimensioni. In generale vale che k-NN degenera all'aumentare delle dimensioni, in generale in numero di NN in una griglia uniforme in uno spazio n-dimensionale √® pari a 2d dove d √® il numero delle dimensioni.


# Dal libro

Il ragionamento basato sui casi (CBR) √® una metodologia per lo sviluppo di sistemi basati sulla conoscenza in cui l'argomento centrale sono i casi o le esperienze passate.
centrale sono i casi o le esperienze passate. Il ragionamento basato su casi significa risolvere problemi basati su esperienze passate, ricordare casi precedenti per guidare la soluzione di problemi
esperienze passate, ricordando casi precedenti per guidare la soluzione di problemi attuali e adattando
soluzioni passate a nuovi problemi.
La metodologia del ragionamento basato sui casi comprende quattro fasi principali, da cui il nome *Architettura R4* o anche approccio delle quattro R.
![[Case-Based Reasoning - architettura CBR dal libro.png|450]]
1. **Problem**: descrivo il problema da risolvere con una *tupla* di attributi. Il problema √® il punto di partenza dello schema
2. **Retrieve**: passo di recupero dai *previous cases* per recuperare i casi pi√π simili che sono presenti in memoria. 
	1. **Retrieved Case**: ho recuperato un caso simile
		1. **Solved Case**: ho una soluzione proposta
	2. **New Case**: il mio problema non √® simile a nessun caso in memoria
3. **Revise**: avendo la *domain knowledge* posso fare questo passo. Ad esempio provo a dare un antibiotico differente ma questo adattamento ha bisogno di essere costruito con conoscenza del dominio.
	1. Se la soluzione √® adoperabile allora confermo la soluzione, altrimenti fallisco
4. **Retain**: il caso esaminato lo voglio aggiungere in memoria per ampliare la KB? 
	1. Caso fallito: interessante inserirlo cos√¨ un esperto del dominio inserisce la soluzione e lui per la prossima volta sapr√† qualcosa in pi√π.
	2. Retrived Case: non ha senso aggiungere perch√© gi√† lo avevo in memoria gi√† molto simile e diventa uno spreco di memoria oltre che, molto peggio, i sistemi vanno in tilt se ci sono troppi dati.

