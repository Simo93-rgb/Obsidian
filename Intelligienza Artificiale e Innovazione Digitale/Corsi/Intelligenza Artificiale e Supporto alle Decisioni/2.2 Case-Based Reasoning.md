Il **CBR** Ã¨ una metodologia per risolvere problemi nuovi adattando le soluzioni di problemi simili precedenti; conosciuti come *sistemi esperti*.

![[Case-Based reasoning - CBRschema 2.png|350]]

>â€œ.... transferring knowledge from past problem solving episodes to new problems that share significant aspects with corresponding past experience and using the transferred knowledge to construct solutions to new problems.â€
>Carbonell, 1986
## Esempi di CBR
- **Classificazione** $\rightarrow$ di un paziente clinico in base alla sintomatologia/esami
- **Soluzione Compilata** $\rightarrow$ ossia la spiegazione del problema $x$ Ã¨ derivabile da quello giÃ  visto col problema $y$
- **Valutazione del Valore** $\rightarrow$ ossia verificare il valore di qualcosa osservando l'ambiente
- **Giustificare coi Precedenti** $\rightarrow$ ossia risolvere il problema nello stesso modo in cui si Ã¨ risolto un precedente. Un po' come accade nella legislatura anglosassone. 
- **Valutazione delle Opzioni** $\rightarrow$ ossia valutare le possibili conseguenze in base a cosa Ã¨ successo nei casi simili. "*Se attaccassimo la base missilistica Cuba/Russia otterremo una situazione come Pearl Harbor*"

#### Architettura R4
![[Case-Based Reasoning - architettura CBR dal libro.png|400]]
0. **Problem**: descrivo il problema da risolvere con una *tupla* di attributi. Il problema Ã¨ il punto di partenza dello schema
1. **Retrieve**: passo di recupero dai *previous cases* per recuperare i casi piÃ¹ simili che sono presenti in memoria. 
	1. **Retrieved Case**: ho recuperato un caso simile
		1. **Solved Case**: ho una soluzione proposta
	2. **New Case**: il mio problema non Ã¨ simile a nessun caso in memoria
2. **Reuse**: se ho un caso simile lo uso altrimenti vado al revise.
3. **Revise**: avendo la *domain knowledge* posso fare questo passo. Ad esempio provo a dare un antibiotico differente ma questo adattamento ha bisogno di essere costruito con conoscenza del dominio.
	1. Se la soluzione Ã¨ adoperabile allora confermo la soluzione, altrimenti fallisco
4. **Retain**: il caso esaminato lo voglio aggiungere in memoria per ampliare la KB? 
	1. Caso fallito: interessante inserirlo cosÃ¬ un esperto del dominio inserisce la soluzione e lui per la prossima volta saprÃ  qualcosa in piÃ¹.
	2. Retrieved Case: non ha senso aggiungere perchÃ© giÃ  lo avevo in memoria giÃ  molto simile e diventa uno spreco di memoria oltre che, molto peggio, i sistemi vanno in tilt se ci sono troppi dati.
CuriositÃ , il primo schema Ã¨ del 1993! 

# Retrieve
### Come rappresento i casi?
Un caso Ã¨ un insieme di attributi e quindi la prima cosa da fare Ã¨ decidere quali e quanti attributi voglio avere per definire i casi. Gli attributi vengono chiamati *features*. Nel caso di un auto, ad esempio, posso avere un record (tupla, oggetto...) contenente etÃ , cilindrata, potenza, colore, modello, marca etc. 
La *rappresentazione minima* consiste nel salvare la descrizione del caso e la sua soluzione. Posso avere delle *estensioni* per ampliare la conoscenza come ad esempio link ad altri casi, contesto, outcome relativi (fallimento, successo). 
![[Case-Based Reasoning - esempio struttura casi con CBRWorks.png|400]]
#### Indicizzazione
Le strategie di indicizzazione servono per recuperare i casi e per come eseguire il match. Quando si indicizza bisogna capire quali sono le features necessarie per discriminare i casi. 

## Modelli di Memoria
Esistono vari modi per recuperare i casi:
- [[2.2 Case-Based Reasoning#Memoria Piatta|Memoria Piatta]]
- Memorie Strutturate
	- [[2.2 Case-Based Reasoning#Decision Tree|Alberi di decisione (Classificazione)]]
	- k-d tree
- Database Relazionale/Oggetti
- Diversi Algoritmi di ricerca
	- L'algoritmo dipenderÃ  da cosa cerco e quale complessitÃ  posso tollerare

### Memoria Piatta
I casi saranno delle tuple di features salvate. In sostanza la mia memoria Ã¨ un grosso insieme di features e il mio caso sarÃ  una tupla che punta a tutte le features che descrivono il caso. Una sorta di array di puntatori che puntano agli attributi desiderati. Poi quali algoritmi e che complessitÃ  dipende dall'implementazione. 

### Decision Tree
Spoiler: nel machine learning sono importantissimi. Un albero di decisione, o DT (Decision Tree), Ã¨ un albero dove:
- I nodi sono attributi
- Gli archi uscenti sono etichettati con condizioni sui valori dell'attributo
Questi alberi sono spesso usati per problemi di classificazione dove la soluzione Ã¨ appunto una classe (paziente di classe semplice o classe complessa?). Le foglie dell'albero indicizzano un insieme di casi e tengo traccia di quanti casi ci sono nelle varie classi (soluzioni). 
Come preannunciato in ML Ã¨ frequente questo tipo di struttura e un algoritmo molto noto Ã¨ il C4.5 (si for tu faive ðŸ˜‚).

![[Case-Based Reasoning - Esempio Decision Tree Tennis.png|450]]
Dando in pasto questa tabella ad un algoritmo C4.5 otterremmo, ad esempio, questo albero![[Case-Based Reasoning - Albero del tennis.png|400]]
Rispettivamente da sinistra a destra: (D1,D5) (D2,D3,D4) (D6,D7,D8,D9) (D10,D11) (D12,D13,D14)
Ok, tutto bello, ma cosa me ne faccio? Ãˆ utilissimo nel passo di retrieve in quanto se il caso nuovo ha tutti gli attributi allora mi basta navigare l'albero e trovare la classe corrispondente. Ma anche nella situazione in cui il caso Ã¨ incompleto, ad esempio manca il dato umiditÃ , posso comunque navigare e dove non ho piÃ¹ una evidenza mi basterÃ  prendere tutto il sotto albero a partire dal dato mancante. In questo ultimo caso avendo tre classi su cinque che dicono di giocare allora la soluzione Ã¨ ragionevolmente quella di giocare. 
# SimilaritÃ  e Distanza
Cosa significa che due casi sono simili fra di loro? Possiamo impostare un parallelismo fra distanza e similaritÃ  per poi misurare quest'ultima in termini di distanza. Una metrica o distanza Ã¨ una una funzione su un insieme $X$ definita come $d: X\times X\rightarrow \mathbb{R}$ che rispetta questi requisiti: $$\begin{align}d(x,y)=0\Leftrightarrow x=y\\d(x,y)\le d(z,x)+d(z,y)\end{align}$$Corollari: $$\begin{align}1.&\quad 1. d(x,y) \geq 0 \\ 2.&\quad d(x,y) = d(y,x) \text{ Simmetria}\end{align}$$
##### Tipi di Distanze
Definiamo le distanze per un generico spazio $\mathbb{R}^n$:
1. Distanza di Manhattan $\rightarrow \sum_{i=1}^n{|x_i-y_i|}$
2. Distanza Euclidea $\rightarrow \sqrt{\sum_{i=1}^n{|x_i-y_i|}^2}$
3. Distanza di Minkowski $\rightarrow \sqrt[p]{\sum_{i=1}^n{|x_i-y_i|}^p} \text{ con } p\geq1$
4. Distanza discreta di overlap $d(x,y)=\begin{cases}0 \text{ se }x=y\\ 1 \text{ se } x\neq y\end{cases}$ 

## Matching
Ogni caso ha $n$ attributi chiamati features, questi possono essere visti come punti in uno spazio $\mathbb{R}^n$. Con questa nozione posso misurare una distanza fra casi esattamente come misurerei una distanza fra due punti nello spazio. 
Ci sono tecniche basate k-NN (k Nearest Neighbour).
### k-NN
Si definisce una funzione di distanza tra i valori di ogni features e successivamente posso misurare la distanza fra le features del caso in input e quelli nella KB; eventualmente si possono definire dei pesi per differenziare l'importanza di delle features. Ora si scelgono i $k$ casi piÃ¹ vicini al target e si usano le loro soluzioni come base per la soluzione del caso target. 
![[Case-Based Reasoning - kNN a due dimensioni.png|400]]
#### Diagrammi di Voronoi
Divido il piano in regioni in base ad un insieme di punti dato e ad una funzione di distanza $d$. Ogni regione o partizione $R$ Ã¨ associata ad un punto $x$ e $\forall y\in R$ si ha che $x$ Ã¨ il punto piÃ¹ vicino ad $y$ rispettando la distanza $d$.
![[Case-based Reasoning - Voronoi.png|400]]
#### Pesatura Attributi
Se $X$ e $Y$ sono ugualmente importanti, la distanza aumenta allo stesso modo in entrambe le direzioni (circonferenza)![[Case-Based Reasoning - pesatura attributi circonferenza.png|250]]Se $Y$ Ã¨ piÃ¹ importante di $X$, piccole variazioni di $Y$ mi rendono i punti piÃ¹ distanti su quell'asse e quindi viene fuori una ellisse schiacciata lungo $Y$; vale il viceversa.
![[Case-Based Reasoning - pesatura Attributi ellissica.png|250]]


##### Tipologia Attributi (features)
Possono essere nominali (categorici) o lineari. Nel caso dei nominali abbiamo colori, simboli... Mentre i lineari possono essere discreti o continui e nel caso discreto c'Ã¨ un caso che puÃ² confondere: attributi lineari discreti simbolici. Succede quando mappo con dei numeri dei concetti, ad esempio una temperatura alta Ã¨ simbolico ma posso mapparla con 39Â°C. 

### Metriche su Features
![[Case-Base Reasoning - metriche e features.png]]
dove $range_f = val_{max} - val_{min}$ 
Funziona male su features nominali perÃ². In alternativa si puÃ² usare una tabella di similaritÃ  ![[Case-Base Reasoning - Tabella SimilaritÃ  features nominali.png]]

### Heterogeneus Value Distance Metric
![[Case-Base Reasoning - HVDM.png]]
#### Esempio
![[Case-Base Reasoning - esempio HVDM.png]]
$d_f(chiaro,scuro)=0.225=$
$=\sqrt{|\mathbb{P}(M|chiaro)-\mathbb{P}(M|scuro)|^2+|\mathbb{P}(F|chiaro)-\mathbb{P}(F|scuro)|^2}$

## Implementazione k-NN
Siccome la ricerca lineare Ã¨ molto costosa con problemi grandi esiste l'applicazione dei *kd-trees* che Ã¨ $\mathbb{O}(log (n))$ ma siccome l'implementazione Ã¨ incredibilmente fastidiosa da mantenere alla fine lo sweet spot Ã¨ l'utilizzo della ricerca lineare.
Osservazione: se vuoi fare il figo parla di questa parte ma all'esame non viene chiesta.
```c++
// Dichiarazione di una struttura KDTree che contiene un metodo per trovare il vicino piÃ¹ vicino
KDTree root;

// Metodo per trovare il vicino piÃ¹ vicino a un dato punto P
Node NearestNeighbor(Point P)
{
    // Coda di prioritÃ  usata per ottenere nodi in ordine di distanza crescente dal punto P
    PriorityQueue PQ; // coda che minimizza

    // Inizializza la migliore distanza con infinito, cioÃ¨ una distanza molto grande
    float bestDist = infinity; // distanza piÃ¹ piccola vista fino a ora

    // Nodo che rappresenta il miglior vicino trovato fino a ora
    Node bestNode; // vicino piÃ¹ vicino fino a ora

    // Inserisce il nodo radice nella coda di prioritÃ  con distanza 0
    PQ.push(root, 0);

    // Continua fino a quando ci sono nodi nella coda di prioritÃ 
    while (!PQ.empty()) {
        // Estrae il nodo e la distanza (o bound) dalla coda di prioritÃ 
        (node, bound) = PQ.pop();

        // Se la distanza Ã¨ maggiore o uguale alla migliore distanza trovata, restituisce il miglior nodo
        if (bound >= bestDist) return bestNode.p;

        // Calcola la distanza dal punto P al punto del nodo corrente
        float dist = distance(P, node.p);

        // Se questa distanza Ã¨ la migliore, aggiorna bestDist e bestNode
        if (dist < bestDist) {
            bestDist = dist;
            bestNode = node;
        }

        // Testa se il nodo corrente dovrebbe avere figli che potrebbero essere piÃ¹ vicini
        if (node.test(P)) {
            // Inserisce i nodi figli nella coda di prioritÃ  con le distanze aggiornate
            PQ.push(node.left, P[node.feat] - node.thresh);
            PQ.push(node.right, 0);
        } else {
            // Inserisce i nodi figli nella coda di prioritÃ  senza aggiornare la distanza
            PQ.push(node.left, 0);
            PQ.push(node.right, node.thresh - P[node.feat]);
        }
    } // Fine del ciclo while

    // Restituisce il punto del miglior nodo trovato
    return bestNode.p;
} // Fine del metodo NearestNeighbor

```

# Revise
Siccome Ã¨ difficile definire delle strategie generali si cerca di definire delle regole ad-hoc a seconda del dominio. Ci sono due approcci: *transformational adaptation* e *derivational adaptation*.

## Trasformational Adaptation
Supponiamo che nel caso del riuso di un caso noto ho un problema di utilizzo della soluzione, ad esempio paziente allergico all'antibiotico, posso modificare la soluzione o aggiungendo un pezzo alla soluzione:
- Cambia antibiotico X con Y
- Dai antibiotico X ma con farmaco W antistaminico
## Derivational Adaptation
Tengo traccia non solo delle soluzioni ai casi ma anche di come ci sono arrivato e quando cerco nei casi conosciuti riapplico il metodo con cui nel caso noto arrivai al risultato. Ho usato una dimostrazione per assurdo in un caso matematico, se il caso Ã¨ simile la soluzione la cerco riapplicando il metodo per assurdo.

# Retain 
Qui si decide quando si deve apprendere ma anche quando si deve dimenticare un caso. Lo scopo Ã¨ tenere in memoria solo i casi utili altrimenti va in tilt il sistema. Nel Machine Learning e in particolare nel CBR si sente spesso parlare di utilitÃ , di come definirla e di quali siano i suoi limiti. Non sempre vale il concetto che piÃ¹ si sa e meglio Ã¨, ingurgitare qualunque caso, anche se buono, porta a problemi. Prende il nome di *swamping problem* nel CBR e in generale nel ML si chiama *utility problem*.
![[Case-Based Reasoning - swamping problem.png|450]]
La performance dipende da: 
- Tempo di esecuzione
- QualitÃ  della risposta
- Competenza del sistema
Queste tre misure di performance dipendono sia dal numero di casi in memoria sia dalla qualitÃ  dei casi in memoria. Il proble-+1`````````````````
```ma di utilitÃ  Ã¨ trovare il numero di casi e la qualitÃ  dei casi che massimizzano la prestazione del CBR ma siccome non c'Ã¨ una ricetta generale che funziona bisogna esaminare caso per caso. Esistono anche altri problemi minori rispetto al utility problem.

## Curse of Dimensionality
Gli approcci *lazy learning* funzionano tanto peggio quanto maggiore Ã¨ il numero delle dimensioni. In generale vale che k-NN degenera all'aumentare delle dimensioni, in generale in numero di NN in una griglia uniforme in uno spazio n-dimensionale Ã¨ pari a 2d dove d Ã¨ il numero delle dimensioni.


# Dal libro

Il ragionamento basato sui casi (CBR) Ã¨ una metodologia per lo sviluppo di sistemi basati sulla conoscenza in cui l'argomento centrale sono i casi o le esperienze passate.
centrale sono i casi o le esperienze passate. Il ragionamento basato su casi significa risolvere problemi basati su esperienze passate, ricordare casi precedenti per guidare la soluzione di problemi
esperienze passate, ricordando casi precedenti per guidare la soluzione di problemi attuali e adattando
soluzioni passate a nuovi problemi.
La metodologia del ragionamento basato sui casi comprende quattro fasi principali, da cui il nome *Architettura R4* o anche approccio delle quattro R.
![[Case-Based Reasoning - architettura CBR dal libro.png|450]]
1. **Problem**: descrivo il problema da risolvere con una *tupla* di attributi. Il problema Ã¨ il punto di partenza dello schema
2. **Retrieve**: passo di recupero dai *previous cases* per recuperare i casi piÃ¹ simili che sono presenti in memoria. 
	1. **Retrieved Case**: ho recuperato un caso simile
		1. **Solved Case**: ho una soluzione proposta
	2. **New Case**: il mio problema non Ã¨ simile a nessun caso in memoria
3. **Revise**: avendo la *domain knowledge* posso fare questo passo. Ad esempio provo a dare un antibiotico differente ma questo adattamento ha bisogno di essere costruito con conoscenza del dominio.
	1. Se la soluzione Ã¨ adoperabile allora confermo la soluzione, altrimenti fallisco
4. **Retain**: il caso esaminato lo voglio aggiungere in memoria per ampliare la KB? 
	1. Caso fallito: interessante inserirlo cosÃ¬ un esperto del dominio inserisce la soluzione e lui per la prossima volta saprÃ  qualcosa in piÃ¹.
	2. Retrived Case: non ha senso aggiungere perchÃ© giÃ  lo avevo in memoria giÃ  molto simile e diventa uno spreco di memoria oltre che, molto peggio, i sistemi vanno in tilt se ci sono troppi dati.

